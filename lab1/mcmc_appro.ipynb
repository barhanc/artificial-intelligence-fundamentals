{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pyro\n",
    "import pyro.infer\n",
    "import pyro.distributions as dist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import Tensor\n",
    "from pyro.infer.mcmc import MCMC, NUTS\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (16, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./bank_marketing_data.csv\", sep=\";\")\n",
    "df = df.drop([\"duration\"], axis=\"columns\")\n",
    "df = df.replace({\"y\": {\"yes\": 1, \"no\": 0}})\n",
    "y = df.pop(\"y\")\n",
    "df = pd.get_dummies(df, drop_first=False, dtype=\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "categorical_features = df.select_dtypes(include=\"object\").columns\n",
    "numerical_features = df.select_dtypes(exclude=\"object\").columns\n",
    "minmax_scaler = MinMaxScaler()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df, y, test_size=0.3, random_state=0, stratify=y\n",
    ")\n",
    "\n",
    "X_train = minmax_scaler.fit_transform(X_train)\n",
    "X_test = minmax_scaler.transform(X_test)\n",
    "\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 1100/1100 [23:49,  1.30s/it, step size=1.99e-02, acc. prob=0.955]\n"
     ]
    }
   ],
   "source": [
    "X_train = Tensor(X_train)\n",
    "y_train = Tensor(y_train)\n",
    "X_test = Tensor(X_test)\n",
    "y_test = Tensor(y_test)\n",
    "\n",
    "dim = X_train.shape[1]\n",
    "\n",
    "\n",
    "def model(X):\n",
    "    sigma = pyro.sample(\"sigma\", dist.HalfCauchy(scale=1.0))\n",
    "    w = pyro.sample(\"w\", dist.Normal(torch.zeros(dim), sigma * torch.ones(dim)))\n",
    "    b = pyro.sample(\"b\", dist.Normal(0.0, sigma))\n",
    "    y = pyro.sample(\"y\", dist.Bernoulli(logits=(w * X).sum(-1) + b), obs=y_train)\n",
    "    return y\n",
    "\n",
    "\n",
    "nuts_kernel = NUTS(model, adapt_step_size=True)\n",
    "mcmc = MCMC(nuts_kernel, num_samples=1_000, warmup_steps=100)\n",
    "mcmc.run(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0]  loss: 19984.1309\n",
      "[iter 500]  loss: 8095.9268\n",
      "763.2 - 383.0 = 380.20000000000005\n",
      "Profit: 15.17% of max profit\n"
     ]
    }
   ],
   "source": [
    "def model_mle(X):\n",
    "    w = pyro.param(\"w\", torch.zeros(dim))\n",
    "    b = pyro.param(\"b\", Tensor([0.0]))\n",
    "    with pyro.plate(\"X\", X.size(0)):\n",
    "        y = pyro.sample(\"y\", dist.Bernoulli(logits=(w * X).sum(-1) + b), obs=y_train)\n",
    "        return y\n",
    "\n",
    "def guide_mle(data):\n",
    "    pass\n",
    "\n",
    "def train(model, X, guide, lr=0.005, n_steps=1_001):\n",
    "    pyro.clear_param_store()\n",
    "    adam_params = {\"lr\": lr}\n",
    "    adam = pyro.optim.Adam(adam_params)\n",
    "    svi = SVI(model, guide, adam, loss=Trace_ELBO())\n",
    "\n",
    "    for step in range(n_steps):\n",
    "        loss = svi.step(X)\n",
    "        if step % 500 == 0:\n",
    "            print(\"[iter {}]  loss: {:.4f}\".format(step, loss))\n",
    "\n",
    "train(model_mle, X_train, guide_mle, lr=0.005, n_steps=1_000)\n",
    "\n",
    "w_mle = pyro.param(\"w\")\n",
    "b_mle = pyro.param(\"b\")\n",
    "p = torch.sigmoid(X_test @ w_mle + b_mle)\n",
    "p\n",
    "\n",
    "y_pred = (p >= 1 / (1 + a / b)).numpy().astype(\"int64\")\n",
    "\n",
    "add = a * len(y_true[(y_pred == 1) & (y_true.numpy() == 1)])\n",
    "los = b * len(y_true[(y_pred == 1) & (y_true.numpy() == 0)])\n",
    "\n",
    "print(add, \"-\", los, \"=\", add - los)\n",
    "print(f\"Profit: {(add - los) /W_max * 100:.2f}% of max profit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2275, 0.2068, 0.0905,  ..., 0.0601, 0.0688, 0.0444])\n",
      "896.4 - 455.0 = 441.4\n",
      "Profit: 17.62% of max profit\n"
     ]
    }
   ],
   "source": [
    "y_true = y_test\n",
    "\n",
    "W = mcmc.get_samples()[\"w\"]\n",
    "b = mcmc.get_samples()[\"b\"]\n",
    "p = torch.sigmoid(X_test @ W.T + b).mean(1)\n",
    "print(p)\n",
    "a, b = 1.8, 1.0\n",
    "W_mat = np.array([[0.0, a], [0.0, b]])  # payout matrix\n",
    "W_max = a * y_true.sum()\n",
    "\n",
    "y_pred = (p >= 1 / (1 + a / b)).numpy().astype(\"int64\")\n",
    "\n",
    "add = a * len(y_true[(y_pred == 1) & (y_true.numpy() == 1)])\n",
    "los = b * len(y_true[(y_pred == 1) & (y_true.numpy() == 0)])\n",
    "\n",
    "print(add, \"-\", los, \"=\", add - los)\n",
    "print(f\"Profit: {(add - los) /W_max * 100:.2f}% of max profit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.89\n",
      "F1 : 0.42\n",
      "Prc: 0.52\n",
      "Rec: 0.36\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "print(f\"Acc: {accuracy_score(y_true, y_pred):.2f}\")\n",
    "print(f\"F1 : {f1_score(y_true, y_pred):.2f}\")\n",
    "print(f\"Prc: {precision_score(y_true, y_pred):.2f}\")\n",
    "print(f\"Rec: {recall_score(y_true, y_pred):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21354362 0.20899227 0.08939273 ... 0.06072397 0.06908467 0.04326713]\n",
      "912.6 - 472.0 = 440.6\n",
      "Profit: 17.58% of max profit\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(max_iter=1_000)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "p = logreg.predict_proba(X_test)[:, 1]\n",
    "print(p)\n",
    "y_pred = (p >= 1 / (1 + a / b)).astype(\"int64\")\n",
    "\n",
    "add = a * len(y_true[(y_pred == 1) & (y_true.numpy() == 1)])\n",
    "los = b * len(y_true[(y_pred == 1) & (y_true.numpy() == 0)])\n",
    "\n",
    "print(add, \"-\", los, \"=\", add - los)\n",
    "print(f\"Profit: {(add - los) /W_max * 100:.2f}% of max profit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.89\n",
      "F1 : 0.43\n",
      "Prc: 0.52\n",
      "Rec: 0.36\n"
     ]
    }
   ],
   "source": [
    "print(f\"Acc: {accuracy_score(y_true, y_pred):.2f}\")\n",
    "print(f\"F1 : {f1_score(y_true, y_pred):.2f}\")\n",
    "print(f\"Prc: {precision_score(y_true, y_pred):.2f}\")\n",
    "print(f\"Rec: {recall_score(y_true, y_pred):.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
